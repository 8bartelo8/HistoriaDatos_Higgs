{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion a Machine Learning (ML)\n",
    "\n",
    "En Machine learning, computadoras aplican tecnicas de aprendizaje estadistico para automaticamente reconocer patrones en los datos.\n",
    "\n",
    "Estas tecnicas se pueden utilizar para predecir, clasificar, ajustar modelos, descubrir patrones y reducir dimencionalidad.\n",
    "\n",
    "Para ello utilizaremos la libreria Scikit-learn:\n",
    "\n",
    "[![](files/scikit-learn-logo.png)](http://scikit-learn.org/stable/index.html)\n",
    "\n",
    "### Funciones de visualizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grafica_KMeans(X1,X2,Y,clf):\n",
    "    X1=X[:, 0]\n",
    "    X2=X[:, 1]\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = X1.min()-1, X1.max() +1\n",
    "    y_min, y_max = X2.min()-1, X2.max() +1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "    # obtener colores para sus modelos\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.imshow(Z, interpolation='nearest',\n",
    "               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "               cmap=plt.cm.Paired,\n",
    "               aspect='auto', origin='lower')\n",
    "    # puntos \n",
    "    plt.scatter(X1,X2, c=Y,cmap=plt.cm.Paired)\n",
    "    # centros\n",
    "    mu = clf.cluster_centers_\n",
    "    plt.scatter(mu[:,0], mu[:,1], s=100, c=np.unique(Y),cmap=plt.cm.Paired,lw=2)\n",
    "    # limites de datos\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    return \n",
    "\n",
    "def grafica_SVC(X1,X2,clf):\n",
    "    plt.axis('tight')\n",
    "    x_min = X1.min()\n",
    "    x_max = X1.max()\n",
    "    y_min = X2.min()\n",
    "    y_max = X2.max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                    levels=[-.5, 0, .5])\n",
    "    \n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "# Estos son nuevos!\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster, svm\n",
    "import sklearn.cross_validation as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El panorama!\n",
    "\n",
    "![](files/ml_map.png)\n",
    "\n",
    "## Un poco de lenguaje dentro de ML\n",
    "\n",
    "* Dimensiones en un conjunto de datos se llaman **features** o **variables**.\n",
    "\n",
    "* La esencia del aprendizaje estadistico es identificar los limites de los datos usando matematicas.\n",
    "\n",
    "* Crear un modelo tambien se dice que es \"entrenar un modelo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero, recordar el problema central\n",
    "### Como clasificaremos a estos dos grupos?\n",
    "#### Que se te ocurre?\n",
    "\n",
    "![](files/classificar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### El problema de Clasificacion\n",
    "\n",
    "En ML, categorizar puntos de datos es un problema de classificacion.\n",
    "\n",
    "Normalmente **X** representan los datos y **Y** los valores a predecir.\n",
    "\n",
    "Lo que queremos encontrar es una funcion $f$ tal que $f(X)=Y$, muchas veces esta funcion $f$ es muy dificil de construir con formulas normales y entonces hay que recurrir a trucos, como utilizar informacion estaditica de $X$ y $Y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('files/ejemplo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los datos como X y Y\n",
    "\n",
    "**X** es facil, solo hay que extraer los datos de las columnas relevantes ('X' y 'Y').\n",
    "\n",
    "**Y** es un poco mas dificil, pues son letras 'A' y 'B', tenemos que convertirlas en numeros que la computadora pueda entender, por ejemplo en la clase '0' y '1', para ello utilizaremos **preprocessing.LabelEncoder()** de scikit-learn.\n",
    "\n",
    "Esta funcion le das una lista de clases y te transforma los datos a enteros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transformar X\n",
    "X = df[['X','Y']].values\n",
    "# Transformar Y\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit([\"A\",\"B\"])\n",
    "Y = encoder.transform(df['Tipo'])\n",
    "print('Forma de X: ',X.shape)\n",
    "print('Forma de Y: ',Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A visualizar! (Solo para recordar como son los datos)\n",
    "\n",
    "Con Y, el valor que queremos predecir, podemos asignar colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1],c=Y,cmap=plt.cm.Paired)\n",
    "plt.title('Datos Ejemplo')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo-del-ritmo #1: K-means \n",
    "\n",
    "K-mean es un algoritmo sencillo que podemos utilizar, busca los centros mas \"probables\" y entonces un punto se encuentra en la categoria si se encuentra mas cerca a estos centros.\n",
    "\n",
    "Normalmente es un algoritmo para \"clusterizacion\", un problema de classificacion cuando no conoces el numeros de class, pero lo usaremos asi suponiendo que si sabes (claro).\n",
    "\n",
    "\n",
    "Primero lo instanciamos como una variable **clf**, como clasificador con el numero **2** para indicar dos clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = cluster.KMeans(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i class=\"fa fa-list\"></i> Ahora entra el ML!\n",
    "\n",
    "Los pasos tipicos para usar un algoritmo son:\n",
    "\n",
    "* **clf**, Definir tu modelo de classificacion.\n",
    "* **fit(X,Y)**, Entrenar el algoritmo con datos de prueba (**Train**)\n",
    "* **predict(X)**, Predecir nuevos datos enbase a las caracteristicas que aprendio. Regresara un nuevo arreglo **y_pred**.\n",
    "* **score(X,Y)**, Calcular el error entre el valor predicado y el real. Normalmente esto es $\\| y_{real} - y_{pred}\\|$\n",
    "\n",
    "\n",
    "Para K-means vamos a calcular el error como $1 - \\frac{1}{N}\\sum_i^N | y_{real} - y_{pred}| $, que en otras palabras es sumar todas las diferencias y dividir entre el numero total de datos, por cien.\n",
    "\n",
    "\n",
    "En codigo esto se ve asi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X)\n",
    "# no te preocupes de esta formula\n",
    "error= 1 - np.sum(np.abs(y_pred - Y))/float(len(Y))\n",
    "score = clf.score(X,Y)\n",
    "print(\"Precision es \",error)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar centros\n",
    "y ademas visualizar los centros que encontro, usando **clf.cluster\\_centers\\_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1 = X[:,0]\n",
    "X2 = X[:,1]\n",
    "# sacar centros y visualizar\n",
    "mu = clf.cluster_centers_\n",
    "plt.scatter(mu[:,0], mu[:,1], s=100, c=np.unique(y_pred),cmap=plt.cm.Paired)\n",
    "# puntos predicados\n",
    "plt.scatter(X1,X2, c=y_pred,cmap=plt.cm.Paired)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espacios de classificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grafica_KMeans(X1,X2,Y,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que llega a 0? Que significa?\n",
    "\n",
    "## <i class=\"fa fa-eye\"></i> Ojo! No se puede confiar de classificadores que tengan 0 error!!! (Ya veremos por que)\n",
    "\n",
    "## Actividad!\n",
    "\n",
    "* Aplicar el algoritmo K-means a los datos de Iris completos!\n",
    "* Cual score consiguen? Cual es el error?\n",
    "* Visualizar los centros! (Recuerda que solo puedes usar 2 variables)\n",
    "\n",
    "Usa el archivo **'files/iris_full.csv'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i class=\"fa fa-question-circle\"></i>  Por que no queremos 100%?\n",
    "###  Este problema se llama \"Overfitting\" \n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/plot_underfitting_overfitting_0011.png)\n",
    "\n",
    "\n",
    "* Imagen 1, es un modelo lineal, ajusta una linea al modelo, usando 2 variables. El error es cercano a **0.4**.\n",
    "* Imagen 2, es un modelo polynomial de grado 4, es una curva no muy complicada de 5 variables. El error es cerca de **0.04 **\n",
    "* Imagen 2, es un modelo polynomial de grado 15, es una curva no muy complicada de 5 variables. El error es cerca de $1.8\\times 10^8$.\n",
    "\n",
    "## Que modelo prefiririas?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i class=\"fa fa-list\"></i>   Pasos para un tipico algoritmo ML:\n",
    "\n",
    "* **clf**, Crear un modelo\n",
    "* **cv.train_test_split(X,Y,test_size=0.90)**,Particionar tus datos en diferentes pedazos (10% entrenar **X_train,Y_train** y 90% prueba **X_test,Y_test**).\n",
    "* **fit(X_train,Y_train)**, Entrenar tu modelo sobre cada pedazo de los datos\n",
    "* **predict(X_test)** Predice!\n",
    "* **score(X_test,Y_test)**, conseguir valor de prediccion.\n",
    "\n",
    "\n",
    "## Intentemos estos nuevos pasos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modelo\n",
    "clf = cluster.KMeans(2)\n",
    "# Dividir daots\n",
    "X_train,X_test, Y_train, Y_test= cv.train_test_split(X,Y,test_size=0.90)\n",
    "# entrenar y predecir\n",
    "clf.fit(X_train,Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# precision y score\n",
    "error= 1 - np.sum(np.abs(y_pred - Y_test))/float(len(Y_test))\n",
    "score = clf.score(X_test,Y_test)\n",
    "print(\"Precision es \",error)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevo espacio de classificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X[:,0]\n",
    "X2 = X[:,1]\n",
    "grafica_KMeans(X1,X2,Y,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una ultima herramienta: KFold-Validation\n",
    "\n",
    "![](files/4fold3class.jpg)\n",
    "![](files/kfold-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i class=\"fa fa-list\"></i>  Finalmente, Pasos para un tipico algoritmo ML:\n",
    "\n",
    "* **clf**, Crear un modelo\n",
    "* **cv.train_test_split(X,Y,test_size=0.90)**,Particionar tus datos en diferentes pedazos (10% entrenar **X_train,Y_train** y 90% prueba **X_test,Y_test**).\n",
    "* **fit(X_train,Y_train)**, Entrenar tu modelo sobre cada pedazo de los datos\n",
    "* **predict(X_test)** Predice!\n",
    "* **cv.cross_val_score(clf,X,Y,cv=10)**, conseguir valor de prediccion de 10 classificadores, usando KFold=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modelo\n",
    "clf = cluster.KMeans(2)\n",
    "# dividir\n",
    "X_train,X_test, Y_train, Y_test= cv.train_test_split(X,Y,test_size=0.90)\n",
    "# entrenar y predecir\n",
    "clf.fit(X_train,Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# resultados\n",
    "error= 1 - np.sum(np.abs(y_pred - Y_test))/float(len(Y_test))\n",
    "resultados = cv.cross_val_score(clf,X,Y, cv=10)\n",
    "print(\"Precision es \",error)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X[:,0]\n",
    "X2 = X[:,1]\n",
    "grafica_KMeans(X1,X2,Y,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De nuevo\n",
    "## Actividad!\n",
    "\n",
    "* Aplicar el algoritmo K-means a los datos de Iris completos!\n",
    "* Utilizar KFold y division de datos.\n",
    "* Cual score promedio consiguen? Cual es el error?\n",
    "\n",
    "Usa el archivo **'files/iris_full.csv'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algoritmo-del-ritmo #2: SVC\n",
    "## Support Vector Classifier \n",
    "\n",
    "Suena complicado pero sigue una idea muy sencilla, tratar de dividir a los datos por una linea o curva, dando un \"margen de error\". Visualmente veremos a que se refiere este margen de error.\n",
    "\n",
    "Podemo crearlo usando el codigo\n",
    "\n",
    "``` python\n",
    "clf = svm.SVC(kernel=tipo)\n",
    "```\n",
    "donde **tipo = 'linear' o 'poly' o 'rbf'**.\n",
    "\n",
    "## Modelo Lineal\n",
    "\n",
    "Es decir usar lineas para hacer nuestra classificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X)\n",
    "score = clf.score(X,Y)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ejeX = X[:, 0]\n",
    "ejeY = X[:, 1]\n",
    "plt.scatter(ejeX,ejeY, c=Y, zorder=10, cmap=plt.cm.Paired)\n",
    "grafica_SVC(ejeX,ejeY,clf)\n",
    "plt.title('Grafica de decision - Lineal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Polynomial\n",
    "\n",
    "Aqui usaremos lineas curvas que siguen un polinomio de grado tres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='poly',degree=3)\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X)\n",
    "score = clf.score(X,Y)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ejeX = X[:, 0]\n",
    "ejeY = X[:, 1]\n",
    "plt.scatter(ejeX,ejeY, c=Y, zorder=10, cmap=plt.cm.Paired)\n",
    "grafica_SVC(ejeX,ejeY,clf)\n",
    "plt.title('Grafica de decision - Poly')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo RBF\n",
    "\n",
    "**RBF** significa **Radial Basis Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X)\n",
    "score = clf.score(X,Y)\n",
    "print(\"Score es \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ejeX = X[:, 0]\n",
    "ejeY = X[:, 1]\n",
    "plt.scatter(ejeX,ejeY, c=Y, zorder=10, cmap=plt.cm.Paired)\n",
    "grafica_SVC(ejeX,ejeY,clf)\n",
    "plt.title('Grafica de decision - RBF')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad!\n",
    "\n",
    "* Aplicar el algoritmo SVC a los datos de Iris completos!\n",
    "* Usar Kfold, cross_validation y division de datos\n",
    "* Cual score consiguen? Cual es el error?\n",
    "* Que ventajas/desventajas ven de usar un modelo lineal/poly/RBF?\n",
    "\n",
    "Usa el archivo **'files/iris_full.csv'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Visualizar el score conforme el numero de K's (centros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks =[ 2,5,8,10,20,40,60,80,100]\n",
    "error=[]\n",
    "for k in ks:\n",
    "    kmeans = cluster.KMeans(k)\n",
    "    kmeans.fit(X)\n",
    "    error.append(kmeans.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ks,error,'-o')\n",
    "plt.xlabel('K-centros')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
